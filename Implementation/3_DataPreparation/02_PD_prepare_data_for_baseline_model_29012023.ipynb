{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5oANeBJE0OJlssrk8DtP7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-O4HHSj0DvBk","executionInfo":{"status":"ok","timestamp":1676397870448,"user_tz":-60,"elapsed":22600,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"423006a8-8855-404e-f978-51eb95a1daba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#================================================================#\n","#============ Preparacion de datos modelo baseline ==============#\n","#================================================================#\n","\n","#====================== Import de librerias =====================#\n","\n","import random\n","import os\n","import json\n","import gzip\n","import pandas as pd\n","from urllib.request import urlopen\n","import datetime\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from datetime import date\n","import glob\n","import numpy as np\n","import torch\n","import pandas as pd\n","import numpy as np\n","import csv\n","import os\n","import scipy.sparse as sp\n","from typing import Tuple, Dict, Any, List\n","from tqdm import tqdm, trange\n","from IPython import embed\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","from sklearn import preprocessing\n","\n","\n","# Definicion de hiperparametros\n","hparams = {\n","    'batch_size':64,\n","    'num_epochs':12,\n","    'hidden_size': 32,\n","    'learning_rate':1e-4,\n","}\n","\n","# we select to work on GPU if it is available in the machine, otherwise will run on CPU\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","# Nombre de columnas\n","col_names = {\"col_id_product\": \"asin\",\n","             \"col_id_reviewer\": \"reviewerID\",\n","             \"col_unix_time\": \"timestamp\",\n","             \"col_year\": \"year\",\n","             \"col_rating\": \"overall\"}\n","\n","# Path de datos\n","path_data= \"/content/drive/MyDrive/postgraduate/Trabajo_final/data\"\n","\n","# Numero de zero positions \n","num_samples=199\n","\n","#============ Definicion de funciones de extraccion y tratamiento ============#\n","\n","def load_src_data(archivo):\n","\n","  '''\n","  Funcion que importa datasets. \n","  '''\n","\n","  ### Import de información\n","  df = pd.read_pickle(archivo)\n","\n","  return df\n","\n","def preprocess_data(df, meta):  \n","  # Preprocesamos el dataset\n","  # Nos quedamos solo con usuario producto y time stamp\n","  # Pasamos ids a numerico\n","  # Los ids de producto y usuario no pueden ser los mismos, los transformamos para que el minimo id de producto se +1 el maximo de usuario\n","\n","  data = df[[col_names[\"col_id_reviewer\"], col_names[\"col_id_product\"],  col_names[\"col_rating\"],  col_names[\"col_unix_time\"]]]\n","\n","  # Aplicamos una lambda a la columna de rating para transformar los valores a 0 o 1\n","  data.loc[:, col_names[\"col_rating\"]] = data[col_names[\"col_rating\"]].apply(lambda x: 1 if x > 0 else 0)\n","\n","  # Convertimos la columna de tiempo a formato fecha\n","  data.loc[:, col_names[\"col_unix_time\"]] = pd.to_datetime(data[col_names[\"col_unix_time\"]])\n","\n","  # Codificación de etiquetas para el usuario\n","  le_usuario = preprocessing.LabelEncoder()\n","  le_usuario.fit(data[col_names[\"col_id_reviewer\"]])\n","  data.loc[:, col_names[\"col_id_reviewer\"]] = le_usuario.transform(data[col_names[\"col_id_reviewer\"]]).astype('int32')\n","\n","  # Codificación de etiquetas para el producto\n","  le_producto = preprocessing.LabelEncoder()\n","  le_producto.fit(data[col_names[\"col_id_product\"]])\n","  data.loc[:, col_names[\"col_id_product\"]] = le_producto.transform(data[col_names[\"col_id_product\"]]).astype('int32')\n","  meta.loc[:, col_names[\"col_id_product\"]] = le_producto.transform(meta[col_names[\"col_id_product\"]]).astype('int32')\n","\n","  add_dims = 0\n","\n","  # Convertimos la data a formato numpy\n","  data = data.to_numpy()\n","\n","  for i in range(data.shape[1] - 2):  # do not affect to timestamp\n","      # Hacemos que los valores empiecen desde 0\n","      data[:, i] -= np.min(data[:, i])\n","      # Re-indexamos\n","      data[:, i] += add_dims\n","      add_dims = np.max(data[:, i]) + 1\n","\n","  dims_usuarios_productos = np.max(data[:,:2], axis=0) + 1\n","\n","  meta.loc[:, col_names[\"col_id_product\"]] = meta[col_names[\"col_id_product\"]].apply(lambda x: x + dims_usuarios_productos[0]).astype('int32')\n","\n","\n","  print( \"\\n\",\"Minimo id de usuario: \", np.min(data[:,0]), \"\\n\",\n","        \"Maximo id de usuario: \", np.max(data[:,0]), \"\\n\",\n","        \"Minimo id de producto: \", np.min(data[:,1]), \"\\n\",\n","        \"Maximo id de producto: \", np.max(data[:,1]), \"\\n\",)\n","  \n","  return (data, meta, dims_usuarios_productos)\n","\n","def build_adj_mx(n_feat:int, data:np.ndarray) -> sp.dok_matrix :\n","    \"\"\"\n","    Esta funcion construye una matriz de adyacencia a partir de los datos de entrada.\n","    La matriz de adyacencia es una representacion simetrica de las interacciones entre los usuarios y productos\n","    y también las interacciones entre productos y cualquier información adicional.\n","\n","    :param n_feat: El número de características presentes en los datos de entrada (número de columnas)\n","    :param data: La matriz de datos de entrada, donde cada fila representa una interacción entre un usuario y un producto.\n","    :return: La matriz de adyacencia, representada como un objeto dok_matrix, que es una estructura eficiente para construir matrices sparse.\n","    \"\"\"\n","\n","    # Instanciamos el objeto train_mat como una dok_matrix\n","    # Una estructura eficiente para construir matrices sparse\n","    train_mat = sp.dok_matrix((n_feat, n_feat), dtype=np.float32)\n","    for x in tqdm(data, desc=f\"BUILDING ADJACENCY MATRIX...\"):\n","        # rellanamos la matriz, al ser simetrica rellenamos primero con logica usuario-producto y luego con logica producto-usuario\n","        train_mat[x[0], x[1]] = 1.0\n","        train_mat[x[1], x[0]] = 1.0\n","        # IDEA: Tratamos las caracteristicas que no son usuario o producto de forma diferente porque no consideramos\n","        #  las interacciones entre contextos\n","        # Añadimos informacion extra a parte de la interacion usuario producto (aqui podria ir el rating)\n","        if data.shape[1] > 2:\n","            for idx in range(len(x[2:])):\n","                train_mat[x[0], x[2 + idx]] = 1.0\n","                train_mat[x[1], x[2 + idx]] = 1.0\n","                train_mat[x[2 + idx], x[0]] = 1.0\n","                train_mat[x[2 + idx], x[1]] = 1.0\n","\n","    return train_mat\n","\n","\n","def ng_sample(data: np.ndarray, dims: list, num_ng:int=4) -> Tuple[np.ndarray, sp.dok_matrix]:\n","  \"\"\"\n","  Crea una matriz de interacciones de usuario-producto (rating) y aplica un muestreo negativo.\n","  \n","  Args:\n","  data: np.ndarray, con las interacciones usuario-producto.\n","  dims: lista, con los valores mínimo y máximo de los productos y usuarios.\n","  num_ng: int, número de interacciones negativas que se quieren generar por cada interacción positiva.\n","  \n","  Returns:\n","  np.ndarray, con las interacciones usuario-producto incluyendo las interacciones negativas generadas.\n","  sp.dok_matrix, con la matriz de interacciones usuario-producto.\n","  \"\"\"\n","\n","  # Creación de la matriz de interacciones positivas\n","  rating_mat = build_adj_mx(dims[-1], data)\n","  interactions = []\n","  min_item, max_item = dims[0], dims[1]\n","  for num, x in tqdm(enumerate(data), desc='Performando muestreo negativo...'):\n","      # Añade la interacción positiva al arreglo de interacciones\n","      interactions.append(np.append(x, 1))\n","      for t in range(num_ng):\n","          # Selecciona un producto al azar para generar una interacción negativa\n","          j = np.random.randint(min_item, max_item)\n","          # Verifica que la interacción no sea una interacción positiva previa\n","          while (x[0], j) in rating_mat or j == int(x[1]):\n","              j = np.random.randint(min_item, max_item)\n","          # Añade la interacción negativa al arreglo de interacciones\n","          interactions.append(np.concatenate([[x[0], j], x[2:], [0]]))\n","  # Devuelve la matriz con todas las interacciones y la matriz dispersa con las interacciones positivas\n","  return np.vstack(interactions), rating_mat\n","\n","\n","def create_test_no_interactions(train_x: np.ndarray, test_x: np.ndarray, dims_usuarios_productos: Tuple[int, int],  num_samples: int) -> np.ndarray:\n","    \"\"\"\n","    Esta funcion se encarga de crear de manera eficiente un dataset que contenga las interacciones usuario-producto en test que no se hayan producido.\n","    \n","    Argumentos:\n","        train_x (np.ndarray): matriz de entrenamiento con las interacciones usuario-producto previas\n","        test_x (np.ndarray): matriz de prueba con las interacciones usuario-producto previas\n","        dims_usuarios_productos (Tuple[int, int]): rango de productos y usuarios disponibles\n","    \n","    Retorno:\n","        np.ndarray: una matriz con todas las interacciones usuario-producto en test que no se hayan producido\n","    \"\"\"\n","    from tqdm import tqdm\n","    import random\n","    \n","    # Identificamos los usuarios presentes en la prueba\n","    usuarios_test = np.unique(test_x[:, 0])\n","    # Identificamos el rango de productos disponibles\n","    total_productos = range(dims_usuarios_productos[0]-1, dims_usuarios_productos[1])\n","    \n","    # Recorremos cada usuario presente en la prueba\n","    for usuario in tqdm(usuarios_test):\n","        # Identificamos los productos en los que el usuario ha interactuado previamente en entrenamiento\n","        productos_train = np.unique(train_x[train_x[:, 0] == usuario][:, 1])\n","        # Seleccionamos al azar 199 productos con los que el usuario no ha interactuado previamente\n","        productos_a_machear = random.choices(list(set(total_productos) - set(productos_train)), k=num_samples)\n","        # Creamos una lista de interacciones usuario-producto para este usuario\n","        lista_por_usuario = [[usuario, x] for x in productos_a_machear]\n","        \n","        # Si es el primer usuario, inicializamos una matriz con sus interacciones\n","        if usuario == 0:\n","            zero_positions = np.array(lista_por_usuario)\n","        # Si no es el primer usuario, concatenamos sus interacciones a la matriz existente\n","        else:\n","            zero_positions = np.concatenate((zero_positions, np.array(lista_por_usuario)), axis=0)\n","            \n","    return zero_positions\n","\n","\n","def build_test_set(itemsnoninteracted:list,\n","                   gt_test_interactions: np.ndarray) -> list:\n","    \"\"\"\n","    Construye el conjunto de pruebas para un usuario dado\n","    :param itemsnoninteracted: lista de items que no han sido interactuados por el usuario\n","    :param gt_test_interactions: arreglo numpy con las interacciones verdaderas del usuario para pruebas\n","    :return: lista de arreglos numpy con interacciones positivas y negativas para cada usuario\n","    \"\"\"\n","    # max_users, max_items = dims \n","    test_set = []\n","    # Recorre cada par de interacciones verdaderas y items no interactuados\n","    for pair, negatives in tqdm(zip(gt_test_interactions, itemsnoninteracted), desc=\"BUILDING TEST SET...\"):\n","        # AGREGA EL CONJUNTO DE PRUEBAS PARA UN SOLO USUARIO\n","        # Elimina el item que si fue interactuado\n","        negatives = np.delete(negatives, np.where(negatives == pair[1]))\n","        # Crea una matriz con la interacción verdadera y items no interactuados\n","        single_user_test_set = np.vstack([pair, ] * (len(negatives)+1))\n","        single_user_test_set[:, 1][1:] = negatives\n","        test_set.append(single_user_test_set.copy())\n","    return test_set\n","\n","\n","\n","class PointData(Dataset):\n","    def __init__(self,\n","                 data: np.ndarray,\n","                 dims: list) -> None:\n","        \"\"\"\n","        Dataset formatter adapted point-wise algorithms\n","        Parameters\n","        \"\"\"\n","        super(PointData, self).__init__()\n","        self.interactions = data\n","        self.dims = dims\n","\n","    def __len__(self) -> int:\n","        return len(self.interactions)\n","        \n","    def __getitem__(self, index: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Return the pairs user-item and the target.\n","        \"\"\"\n","        return self.interactions[index][:-1], self.interactions[index][-1]\n","\n","def split_train_test(data: np.ndarray,n_users: int) -> Tuple[np.ndarray, np.ndarray]:\n","    # Split and remove timestamp\n","    train_x, test_x = [], []\n","    for u in trange(n_users, desc='spliting train/test and removing timestamp...'):\n","        # Filtramos al usuario dentro del dataset\n","        user_data = data[data[:, 0] == u]\n","        # Ordenamos por fecha de interaccion\n","        sorted_data = user_data[user_data[:, 2].argsort()]\n","\n","        # Si solo existe una review, introduce esta interaccion en el train\n","        if len(sorted_data) == 1:\n","            train_x.append(sorted_data[0][:-1])\n","\n","        else:\n","          # Si la ultima interaccion tiene score de 1 puede ir a test, si no, todo a train\n","          if sorted_data[-1][-2]==1:\n","            # Introduce todas las interacciones salvo la ultima en el train\n","            train_x.append(sorted_data[:-1][:, :-1])\n","            # La ultima interaccion corresponde al test\n","            test_x.append(sorted_data[-1][:-1])\n","\n","          else:\n","            train_x.append(sorted_data[:, :-1])\n","\n","    return np.vstack(train_x), np.stack(test_x)\n","\n","\n","#============ Definicion de modelado ============#\n","\n","#============ Definicion de visualizacion ============#"],"metadata":{"id":"Hap-7GvAD3xD","executionInfo":{"status":"ok","timestamp":1676397874799,"user_tz":-60,"elapsed":4356,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Lectura de la información\n","file_to_src = glob.glob(path_data+'/SRC*.pkl')\n","df=load_src_data(file_to_src[0])# Reviews\n","meta=load_src_data(file_to_src[1])# Metadatos"],"metadata":{"id":"cgR80A-3GMHR","executionInfo":{"status":"ok","timestamp":1676397882221,"user_tz":-60,"elapsed":2962,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Preprocesamiento de reviews y metadatos\n","data, meta, dims_usuarios_productos = preprocess_data(df, meta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDxlv42UL_Np","executionInfo":{"status":"ok","timestamp":1676397882727,"user_tz":-60,"elapsed":515,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"34f02f3d-d42b-4d8d-ae16-40586e56acd3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_column(ilocs[0], value, pi)\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Minimo id de usuario:  0 \n"," Maximo id de usuario:  10758 \n"," Minimo id de producto:  10759 \n"," Maximo id de producto:  14116 \n","\n"]}]},{"cell_type":"code","source":["# Division entre train y test\n","train_x, test_x = split_train_test(data, dims_usuarios_productos[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFfiHFjPV5kx","executionInfo":{"status":"ok","timestamp":1676397906804,"user_tz":-60,"elapsed":20008,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"16defaa3-af18-4c7f-c581-de4259d9b189"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["spliting train/test and removing timestamp...: 100%|██████████| 10759/10759 [00:19<00:00, 549.59it/s]\n"]}]},{"cell_type":"code","source":["train_x=train_x.astype(int)\n","test_x=test_x.astype(int)"],"metadata":{"id":"Iyv3urKm9mnz","executionInfo":{"status":"ok","timestamp":1676397906805,"user_tz":-60,"elapsed":19,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Eliminamos timestamp\n","data=data[:,:-1]"],"metadata":{"id":"2em3axtQnqHf","executionInfo":{"status":"ok","timestamp":1676397906806,"user_tz":-60,"elapsed":19,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# realizamos el negative sampling\n","train_x, rating_mat = ng_sample(train_x[:, :2], dims_usuarios_productos)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1t7MTOwkqsaY","executionInfo":{"status":"ok","timestamp":1676397918449,"user_tz":-60,"elapsed":11661,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"2fd246f1-cb98-45f6-e9f8-559c8e14cbe9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["BUILDING ADJACENCY MATRIX...: 100%|██████████| 91008/91008 [00:01<00:00, 46824.26it/s]\n","Performando muestreo negativo...: 91008it [00:08, 10542.77it/s]\n"]}]},{"cell_type":"code","source":["train_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1F0knufuq8e_","executionInfo":{"status":"ok","timestamp":1676397918450,"user_tz":-60,"elapsed":39,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"3eeaa281-bc41-4c68-e5d8-40705693a11f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0, 10824,     1],\n","       [    0, 11656,     0],\n","       [    0, 13361,     0],\n","       ...,\n","       [10758, 12635,     0],\n","       [10758, 13297,     0],\n","       [10758, 14106,     0]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Creamos el dataset de entrenamiento. Devuelve array con interaccion usuario-producto y si sucedió de verdad\n","train_dataset = PointData(train_x, dims_usuarios_productos)\n","train_dataset[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKBiu72br7uG","executionInfo":{"status":"ok","timestamp":1676397918451,"user_tz":-60,"elapsed":38,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"fcc2f0ea-8bca-45fa-f9a7-57f2845f8e26"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([    0, 11656]), 0)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Se crean interacciones que no se han dado (0's) en datos de test\n","zero_positions=create_test_no_interactions(train_x,test_x, dims_usuarios_productos, num_samples )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d092PdU3QoT1","executionInfo":{"status":"ok","timestamp":1676398033826,"user_tz":-60,"elapsed":82524,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"7ddc5fef-8e65-4fcc-a447-2c8b4b06855a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10759/10759 [01:21<00:00, 132.05it/s]\n"]}]},{"cell_type":"code","source":["zero_positions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pkqo6AY_Rfxj","executionInfo":{"status":"ok","timestamp":1676398033827,"user_tz":-60,"elapsed":31,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"e2d36165-6fb5-4ff1-c81a-4d349305c301"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0, 12227],\n","       [    0, 12919],\n","       [    0, 11297],\n","       ...,\n","       [10758, 13412],\n","       [10758, 11182],\n","       [10758, 13317]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Se crea una lista de listas con los productos por usuario a testear\n","items2compute = []\n","for user in trange(dims_usuarios_productos[0]):\n","    aux = zero_positions[zero_positions[:, 0] == user][:, 1]\n","    items2compute.append(aux[aux >= dims_usuarios_productos[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnNKY-Guzmef","executionInfo":{"status":"ok","timestamp":1676398110583,"user_tz":-60,"elapsed":76784,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"2c1f3c95-36cc-4c15-a092-25cd61627255"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10759/10759 [01:17<00:00, 139.57it/s]\n"]}]},{"cell_type":"code","source":["print(test_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZQK5CsM2OpD","executionInfo":{"status":"ok","timestamp":1676398110584,"user_tz":-60,"elapsed":25,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"6fe99894-06cc-4655-a9be-f13c01a9f82e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[    0 12806     1]\n"," [    1 14064     1]\n"," [    2 12659     1]\n"," ...\n"," [10756 12639     1]\n"," [10757 11148     1]\n"," [10758 14067     1]]\n"]}]},{"cell_type":"code","source":["# Al estas en esta tabla todas las interacciones positivas, no necesito mas a esa ultima columna\n","test_x = test_x[:, :2]\n","test_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OAcb5WF2eT9","executionInfo":{"status":"ok","timestamp":1676398110585,"user_tz":-60,"elapsed":23,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"81c5be21-4da0-4661-b124-0a324e23d8ff"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0, 12806],\n","       [    1, 14064],\n","       [    2, 12659],\n","       ...,\n","       [10756, 12639],\n","       [10757, 11148],\n","       [10758, 14067]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Se construye el test_set definitivo, con las interacciones que han ocurrido y las que no en test set\n","test_x = build_test_set(items2compute, test_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pl-2hRtKzmoY","executionInfo":{"status":"ok","timestamp":1676398112609,"user_tz":-60,"elapsed":2044,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"65a8efbb-4f78-4e31-91f0-408b18665720"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["BUILDING TEST SET...: 10759it [00:02, 5348.72it/s]\n"]}]},{"cell_type":"code","source":["train_dataset.dims"],"metadata":{"id":"70dcbm7DHmbr","executionInfo":{"status":"ok","timestamp":1676398198386,"user_tz":-60,"elapsed":5,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}},"outputId":"a6a0e70c-f9af-42a6-e4a9-8c9f5c07e6c4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10759, 14117], dtype=object)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["test_x[0]"],"metadata":{"id":"wDUd_UzM6nwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Guarda train_dataset y test_x\n","import pickle\n","from datetime import date\n","\n","today = date.today()\n","\n","# Train\n","with open(path_data+\"/\"+\"MOD_baseline_train\"+\"_\"+today.strftime(\"%d%m%Y\")+\".pkl\", 'wb') as handle:\n","    pickle.dump(train_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# Test\n","with open(path_data+\"/\"+\"MOD_baseline_test\"+\"_\"+today.strftime(\"%d%m%Y\")+\".pkl\", 'wb') as f:\n","    pickle.dump(test_x, f)\n","\n","# Meta\n","meta.to_pickle(path_data+\"/\"+\"SRC_meta_Musical_instruments_id_treated\"+\"_\"+today.strftime(\"%d%m%Y\")+\".pkl\")"],"metadata":{"id":"PtCwyWyFXqmL","executionInfo":{"status":"aborted","timestamp":1676397950156,"user_tz":-60,"elapsed":15,"user":{"displayName":"Antonio Sánchez Hernández","userId":"15232433011328852348"}}},"execution_count":null,"outputs":[]}]}