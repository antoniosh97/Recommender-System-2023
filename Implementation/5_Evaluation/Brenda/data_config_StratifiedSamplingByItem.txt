asin               6178
reviewerID        14138
overall               5
unixReviewTime     3622
timestamp          3622
year                  1
dtype: int64

####  zero_positions: Stratified Sampling By Items  ####
(2122224, 2)	-----> num_samples = 456

21-Feb-2023  17:36
MODEL: FACTORIZATION MACHINE
epoch 0:
training loss = 624.3417 | Eval: HR@10 = 0.0583, NDCG@10 = 0.0260 
MODEL: RANDOM
epoch 0:
training loss = 624.3417 | Eval: HR@10 = 0.0644, NDCG@10 = 0.0308 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 1:
training loss = 4.4598 | Eval: HR@10 = 0.0824, NDCG@10 = 0.0504 
MODEL: RANDOM
epoch 1:
training loss = 4.4598 | Eval: HR@10 = 0.0644, NDCG@10 = 0.0297 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 2:
training loss = 0.5116 | Eval: HR@10 = 0.1816, NDCG@10 = 0.1124 
MODEL: RANDOM
epoch 2:
training loss = 0.5116 | Eval: HR@10 = 0.0667, NDCG@10 = 0.0308 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 3:
training loss = 0.4998 | Eval: HR@10 = 0.1530, NDCG@10 = 0.0925 
MODEL: RANDOM
epoch 3:
training loss = 0.4998 | Eval: HR@10 = 0.0662, NDCG@10 = 0.0303 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 4:
training loss = 0.4797 | Eval: HR@10 = 0.1726, NDCG@10 = 0.1035 
MODEL: RANDOM
epoch 4:
training loss = 0.4797 | Eval: HR@10 = 0.0678, NDCG@10 = 0.0309 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 5:
training loss = 0.4572 | Eval: HR@10 = 0.2074, NDCG@10 = 0.1216 
MODEL: RANDOM
epoch 5:
training loss = 0.4572 | Eval: HR@10 = 0.0634, NDCG@10 = 0.0281 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 6:
training loss = 0.4366 | Eval: HR@10 = 0.2057, NDCG@10 = 0.1205 
MODEL: RANDOM
epoch 6:
training loss = 0.4366 | Eval: HR@10 = 0.0652, NDCG@10 = 0.0302 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 7:
training loss = 0.4203 | Eval: HR@10 = 0.2181, NDCG@10 = 0.1272 
MODEL: RANDOM
epoch 7:
training loss = 0.4203 | Eval: HR@10 = 0.0692, NDCG@10 = 0.0311 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 8:
training loss = 0.4093 | Eval: HR@10 = 0.2320, NDCG@10 = 0.1352 
MODEL: RANDOM
epoch 8:
training loss = 0.4093 | Eval: HR@10 = 0.0697, NDCG@10 = 0.0321 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 9:
training loss = 0.3997 | Eval: HR@10 = 0.2300, NDCG@10 = 0.1343 
MODEL: RANDOM
epoch 9:
training loss = 0.3997 | Eval: HR@10 = 0.0661, NDCG@10 = 0.0302 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 10:
training loss = 0.3939 | Eval: HR@10 = 0.2365, NDCG@10 = 0.1377 
MODEL: RANDOM
epoch 10:
training loss = 0.3939 | Eval: HR@10 = 0.0675, NDCG@10 = 0.0304 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 11:
training loss = 0.3865 | Eval: HR@10 = 0.2534, NDCG@10 = 0.1471 
MODEL: RANDOM
epoch 11:
training loss = 0.3865 | Eval: HR@10 = 0.0673, NDCG@10 = 0.0306 
_________________________________________________________________
# Training duration: 1295.7728
