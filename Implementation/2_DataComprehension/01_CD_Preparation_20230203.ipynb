{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Overview [03/02/2023]\n","\n","*version 2*\n","\n","Unified Code:\n","* Detele duplicates\n","* Delete users with less than 10 interactions"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Z9pQmdfJmH_n"},"source":["# Unified code"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#====================== Import de librerias =====================#\n","import os\n","from pathlib import Path\n","import json\n","import gzip\n","import pandas as pd\n","from urllib.request import urlopen\n","import datetime\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import wget\n","import logging\n","\n","logfile = \"project.log\"\n","old_path = os.getcwd()\n","os.chdir(\"..\")\n","execution_path = os.getcwd()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#============ Definicion de valores de configuracion ============#\n","\n","logging.basicConfig(\n","    filename=logfile, \n","    level=logging.DEBUG, \n","    datefmt='%Y-%m-%d %H:%M:%S',\n","    format='%(asctime)s  %(message)s')\n","\n","with open(execution_path/Path(\"1_Datos/urls.json\"), \"r\") as f:\n","    data_info = json.loads(f.readline())\n","# Url de dataset que queremos descargar\n","urls= [data_info[\"url\"]]\n","\n","# Minimo de reviews por usuario\n","min_reviews, min_usuarios = [6,6]\n","\n","# Columns names\n","col_names = {\"col_id_product\": \"asin\",\n","             \"col_id_reviewer\": \"reviewerID\",\n","             \"col_rating\": \"overall\",\n","             \"col_unix_time\": \"unixReviewTime\",\n","             \"col_timestamp\": \"timestamp\",\n","             \"col_year\": \"year\"}\n","\n","csv_filename = execution_path/Path(\"3_DataPreparation/interactions_minR{}_minU{}.csv\".format(min_reviews,min_usuarios))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Audt6LW15nA4"},"outputs":[],"source":["#============ Definicion de funciones de extraccion y tratamiento ============#\n","\n","def get_dataset_basic_info(df, nombre):\n","  '''\n","  Funcion que retorna infomracion de # de clientes, productos y reviews en dataset elegido\n","  '''\n","  aux=len(nombre)\n","  numero_clientes=len(df[col_names[\"col_id_reviewer\"]].unique())\n","  numero_productos=len(df[col_names[\"col_id_product\"]].unique())\n","\n","  lines = [\n","    \"#\"*aux,\n","    nombre.center(aux),\n","    \"#\"*aux,\n","    \"Numero total de clientes: {}\".format(numero_clientes),\n","    \"Numero total de products: {}\".format(numero_productos),\n","    \"Numero total de reviews: {}\".format(df.shape[0])\n","  ]\n","  to_print = \"\"\n","  for line in lines:\n","    to_print+=line+\"\\n\"\n","    logging.debug(line)\n","  return(to_print)\n","\n","def clear_content_logger(logfile):\n","    with open(logfile, 'w'):\n","        pass\n","\n","def load_data_raw():\n","  '''\n","  Funcion que descarga los datasets de las url elegidas. \n","  '''\n","  filename = wget.download(urls[0])\n","  df = pd.read_csv(filename, delimiter=\",\", names=[*col_names.values()][:4])\n","  print(get_dataset_basic_info(df,\"Download the infromation from RAW dataset\"))\n","  os.remove(filename)\n","  \n","  return df\n","\n","def treat_dataset_src(df, min_reviews,info=False):\n","\n","    '''\n","    Funcion que trata el dataset original\n","    Realiza conversiones de tipo\n","    Filtra duplicados (usuarios que han puesto mas de una review sobre un producto el mismo día)\n","    Filtra productos comprados por al menos 3 usuarios\n","    Filtra solo usuarios con mas de X reviews\n","    '''\n","    logging.info(\"Min users per product: {}\".format(min_usuarios))\n","    logging.info(\"Min reviews per user: {}\".format(min_reviews))\n","    \n","    # Conversion de tipo\n","    df[col_names[\"col_rating\"]] = pd.to_numeric(df[col_names[\"col_rating\"]].replace(',','', regex=True))\n","    df[col_names[\"col_timestamp\"]]=df[col_names[\"col_unix_time\"]].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n","    df[col_names[\"col_year\"]]= pd.to_datetime(df[col_names[\"col_unix_time\"]]).dt.year\n","\n","    # Duplicados\n","    df_duplicates = df[[col_names[\"col_id_reviewer\"],col_names[\"col_id_product\"], col_names[\"col_unix_time\"]]].sort_values(by=[col_names[\"col_unix_time\"]], ascending=False)\n","    df = df.drop(df_duplicates[df_duplicates[[col_names[\"col_id_reviewer\"],col_names[\"col_id_product\"]]].duplicated()][col_names[\"col_id_reviewer\"]].index.values.tolist())\n","   \n","    if (info==True):\n","      get_dataset_basic_info(df,\"Informacion tras eliminar duplicados\")\n","\n","    productos_a_eliminar=[1]\n","    clientes_a_eliminar=[1]\n","    iteracion = 1\n","    while (len(productos_a_eliminar)!=0)and(len(clientes_a_eliminar)!=0):\n","\n","      # Minimo de usuarios que han comprado el producto productos \n","      aux=df.groupby([col_names[\"col_id_product\"]])[col_names[\"col_id_reviewer\"]].count().reset_index()\n","      aux2=aux[aux[col_names[\"col_id_reviewer\"]]<min_usuarios].reset_index() # usuarios a eliminar\n","      aux=aux[aux[col_names[\"col_id_reviewer\"]]>=min_usuarios].reset_index() # usuarios a conservar\n","      productos=aux[col_names[\"col_id_product\"]]\n","      df=df[df[col_names[\"col_id_product\"]].isin(productos)]\n","\n","      productos_a_eliminar=aux2[col_names[\"col_id_product\"]]\n","\n","\n","      if (info==True):\n","        get_dataset_basic_info(df,f\"Iteracion: {iteracion}. Informacion tras eliminar productos comprados por menos de {min_usuarios} personas\")\n","\n","      # Seleccionamos los ids de producto que tienen mas de X reviews \n","      aux=df.groupby([col_names[\"col_id_reviewer\"]])[col_names[\"col_rating\"]].count().reset_index()\n","      aux2=aux[aux[col_names[\"col_rating\"]]<min_reviews].reset_index()\n","      aux=aux[aux[col_names[\"col_rating\"]]>=min_reviews].reset_index()\n","      clientes=aux[col_names[\"col_id_reviewer\"]]\n","      df=df[df[col_names[\"col_id_reviewer\"]].isin(clientes)]\n","\n","      clientes_a_eliminar=aux2[col_names[\"col_id_reviewer\"]]\n","\n","      if (info==True):\n","        get_dataset_basic_info(df,f\"Iteracion: {iteracion}. Informacion tras eliminar usuarios con menos de {min_reviews} reviews\")\n","\n","      iteracion+=1\n","\n","    df[col_names[\"col_id_reviewer\"]] = pd.Categorical(df[col_names[\"col_id_reviewer\"]]).codes\n","    df[col_names[\"col_id_product\"]] = pd.Categorical(df[col_names[\"col_id_product\"]]).codes\n","    df.to_csv(csv_filename, index=False)\n","    return df\n","\n","def final_checks(df1):\n","  get_dataset_basic_info(df1,\"Definition of initial dataset after SRC data processing\")\n","  # comprobacion duplicados\n","  df_ratings_item_user = df1.groupby(['reviewerID','asin'])['overall'].agg(cuenta='count').sort_values(['cuenta'], ascending=[False]).reset_index()\n","  df_ratings_item_user = df_ratings_item_user.query('cuenta > 1')\n","  logging.debug(\"validation:\")\n","  logging.debug('number of users with multiple ratings of the same item: ' + str(df_ratings_item_user.reviewerID.count()))\n","\n","  # comprobacion numero de usuarios con minimo min_reviews=3 reviews\n","  aux=df1.groupby([col_names[\"col_id_reviewer\"]])[col_names[\"col_rating\"]].count().reset_index()\n","  aux2=aux[aux[col_names[\"col_rating\"]]<min_reviews].reset_index()\n","  logging.debug(\"comprobacion numero de usuarios con minimo {} reviews: {}\".format(min_reviews,aux2.size))\n","\n","  # comprobacion numero de productos con minimo 3 usuarios\n","  aux=df1.groupby([col_names[\"col_id_product\"]])[col_names[\"col_id_reviewer\"]].count().reset_index()\n","  aux2=aux[aux[col_names[\"col_id_reviewer\"]]<min_usuarios].reset_index() \n","  logging.debug(\"comprobacion numero de prodcutos con minimo {} reviews: {}\".format(min_usuarios, aux2.size))\n","\n","  logging.debug(f\"Total: \" + str(len(df1.index)))\n","  logging.debug(f\"Duplicates1: \" + str(df1.duplicated(subset=[\"asin\", \"reviewerID\", \"overall\", \"timestamp\", \"year\"]).sum()) )\n","  logging.debug(f\"Duplicates2: \" + str(df1.duplicated(subset=[\"asin\", \"reviewerID\", \"overall\"]).sum()) )\n","\n","#============ Visualización ============#\n","\n","def barplot_reviews(df):\n","\n","  '''\n","  Visualizaciones interesantes:\n","  Barplot con el numero de usuarios en funcion del numero de reviews en dataset\n","  '''\n","\n","  # Definicion de dataset\n","  data = pd.DataFrame(df.groupby([col_names[\"col_id_reviewer\"]]).count()).reset_index().groupby([col_names[\"col_rating\"]]).count().reset_index()\n","\n","  # Definicion del objeto fig\n","  fig = go.Figure()\n","\n","  # Gráfica\n","  fig.add_trace(go.Bar(x=data[col_names[\"col_rating\"]],\n","                  y=data[col_names[\"col_id_reviewer\"]],\n","                  name='Rest of world',\n","                  marker_color='rgb(55, 83, 109)'\n","                  ))\n","\n","\n","  fig.update_layout(\n","      title='¿Cuantos usuarios tienen x reviews?',\n","      xaxis_tickfont_size=14,\n","      yaxis=dict(\n","          title='# de usuarios',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      ),\n","      xaxis=dict(\n","          title='# de reviews',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      )\n","  )\n","\n","  return(fig.show())\n","\n","def timeline_reviews(df):\n","\n","  # Definicion de dataset\n","  data = pd.DataFrame(df.groupby([col_names[\"col_year\"]]).count()).reset_index()\n","\n","  # Definicion de objeto figura\n","  fig = go.Figure()\n","\n","  # Definicion de grafica\n","  fig.add_trace(go.Bar(x=data[col_names[\"col_year\"]],\n","                  y=data[col_names[\"col_rating\"]],\n","                  name='Rest of world',\n","                  marker_color='rgb(55, 83, 109)'\n","                  ))\n","\n","\n","  fig.update_layout(\n","      title='¿Cuantas reviews tenemos por año?',\n","      xaxis_tickfont_size=14,\n","      yaxis=dict(\n","          title='# de usuarios',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      ),\n","      xaxis=dict(\n","          title='Año',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      )\n","  )\n","\n","  return(fig.show())\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4045,"status":"ok","timestamp":1674740255216,"user":{"displayName":"Evaristo Broullon Couso","userId":"03016626427730807327"},"user_tz":-60},"id":"QekAp50F8Dv1","outputId":"50ffbc71-0f03-45d1-d9a6-75d997c55b58"},"outputs":[{"name":"stdout","output_type":"stream","text":["#########################################\n","Download the infromation from RAW dataset\n","#########################################\n","Numero total de clientes: 903330\n","Numero total de products: 112222\n","Numero total de reviews: 1512530\n","\n"]}],"source":["if not os.path.exists(csv_filename):\n","    clear_content_logger(logfile)\n","    df = load_data_raw()\n","    df1=treat_dataset_src(df, min_reviews, True)\n","else:\n","    df1 = pd.read_csv(csv_filename)\n","\n","final_checks(df1)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# execute just to delete your logfile\n","handlers = logging.getLogger().handlers[:]\n","for handler in handlers:\n","    handler.close()\n","    logging.getLogger().removeHandler(handler)\n","os.remove(logfile)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1674741011304,"user":{"displayName":"Evaristo Broullon Couso","userId":"03016626427730807327"},"user_tz":-60},"id":"xFM6em8337TH","outputId":"dd2ee363-0b89-4ff5-f67c-4a50aab771cd"},"outputs":[],"source":["barplot_reviews(df1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":220,"status":"ok","timestamp":1674741015142,"user":{"displayName":"Evaristo Broullon Couso","userId":"03016626427730807327"},"user_tz":-60},"id":"a7PuVQsL16Sa","outputId":"af17acb8-41f3-4875-a2b9-20286f790ec8"},"outputs":[],"source":["timeline_reviews(df1)"]},{"cell_type":"markdown","metadata":{"id":"Xo-58eDwHXbm"},"source":["# Joan graficas\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IX7Mt7uA0PPm"},"outputs":[],"source":["#============ Visualización ============#\n","\n","def scatter_user_ratings_count(df, col_names, num_reviews):\n","\n","   # count of ratings per reviewer\n","  data = df.groupby([col_names[\"col_id_reviewer\"]])[col_names[\"col_rating\"]].agg(cuenta='count', mean='mean').sort_values(['cuenta', 'mean'], ascending=[False, False]).reset_index()\n","  data = data.query('cuenta>'+str(num_reviews))\n","  \n","  fig = px.scatter(data, x=col_names[\"col_id_reviewer\"], y='cuenta', color='mean',\n","                 size='mean')\n","\n","  fig.update_layout(\n","      title=\"Count of reviews for reviewers with more than \"+ str(num_reviews) + \" reviews. Showing \"+ str(data.shape[0])  + \" of \" + str(df.shape[0]) + \" ratings\",\n","      yaxis=dict(\n","          title='ratings count',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      ),\n","      xaxis=dict(\n","          title='reviewers',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      )\n","  )\n","  return fig.show()\n","\n","def scatter_user_ratings_mean(df, col_names, num_reviews):\n","\n","   # mean of ratings per reviewer\n","  data = df.groupby([col_names[\"col_id_reviewer\"]])[col_names[\"col_rating\"]].agg(cuenta='count', mean='mean').sort_values(['cuenta', 'mean'], ascending=[False, False]).reset_index()\n","  data = data.query('cuenta>'+str(num_reviews))\n","\n","  fig = px.scatter(data, x=col_names[\"col_id_reviewer\"], y='mean', color='cuenta',\n","                 size='cuenta')\n","\n","  fig.update_layout(\n","      title=\"Mean of reviews for reviewers with more than \"+ str(num_reviews) + \" reviews. Showing \"+ str(data.shape[0])  + \" of \" + str(df.shape[0]) + \" ratings\",\n","      yaxis=dict(\n","          title='ratings mean',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      ),\n","      xaxis=dict(\n","          title='reviewers',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      )\n","  )\n","\n","  return fig.show()\n","\n","def scatter_product_ratings_mean(df, col_names, num_reviews):\n","\n","   # mean of ratings per reviewer\n","  data = df.groupby([col_names[\"col_id_product\"]])[col_names[\"col_rating\"]].agg(cuenta='count', mean='mean').sort_values(['cuenta', 'mean'], ascending=[False, False]).reset_index()\n","  data = data.query('cuenta>'+str(num_reviews))\n","\n","  fig = px.scatter(data, x=col_names[\"col_id_product\"], y='mean', color='cuenta',\n","                 size='cuenta')\n","\n","  fig.update_layout(\n","      title=\"Mean of reviews for products with more than \"+ str(num_reviews) + \" reviews. Showing \"+ str(data.shape[0]) + \" of \" + str(df.shape[0]) + \" ratings\",\n","      yaxis=dict(\n","          title='ratings mean',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      ),\n","      xaxis=dict(\n","          title='products',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      )\n","  )\n","\n","  return fig.show()  \n","\n","def scatter_product_ratings_count(df, col_names, num_reviews):\n","\n","   # count of ratings per reviewer\n","  data = df.groupby([col_names[\"col_id_product\"]])[col_names[\"col_rating\"]].agg(cuenta='count', mean='mean').sort_values(['cuenta', 'mean'], ascending=[False, False]).reset_index()\n","  data = data.query('cuenta>'+str(num_reviews))\n","\n","  fig = px.scatter(data, x=col_names[\"col_id_product\"], y='cuenta', color='mean',\n","                 size='mean')\n","\n","  fig.update_layout(\n","      title=\"Count of reviews for products with more than \"+ str(num_reviews) + \" reviews. Showing \"+ str(data.shape[0])  + \" of \" + str(df.shape[0]) + \" ratings\",\n","      yaxis=dict(\n","          title='ratings count',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      ),\n","      xaxis=dict(\n","          title='products',\n","          titlefont_size=16,\n","          tickfont_size=14,\n","      )\n","  )\n","\n","  return fig.show()  \n"]},{"cell_type":"markdown","metadata":{"id":"0AhUrHovHdgm"},"source":["# Procesado matriz por filas y columnas\n"]},{"cell_type":"markdown","metadata":{"id":"sfz_s-lg0uUG"},"source":["La secuencia sería, eliminar el codigo que peta:\n","\n","zero_positions = np.asarray(np.where(rating_mat.A==0)).T  #devuelve los indices traspuestos de cada posicion\n","print(rating_mat.A)\n","print(zero_positions)\n","print(dims[0])\n","\n","y sustituir este código:\n","\n","items2compute = []\n","for user in trange(dims[0]):\n","    aux = zero_positions[zero_positions[:, 0] == user][:, 1] #devuelve el item\n","    items2compute.append(aux[aux >= dims[0]])\n","\n","por éste:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_CiBqvTU0gr4"},"outputs":[],"source":["\n","   # generate test dataset\n","    items2compute = []\n","    items_zero_per_user = []\n","    for user in trange(dims[0]):\n","        aux1 = rating_mat[user, (dims[0]+1):]        \n","        items_zero_per_user = np.where(aux1.A==0)\n","        aux = items_zero_per_user[:] + (dims[0]+1)\n","        items2compute.append(aux[1])"]}],"metadata":{"colab":{"collapsed_sections":["DSmzUjIFz9VP","57ZTXo1hz_nU","5ykB6Vhu0CH6","0DuJcczD0IAs","J5hl9IdW0KSa"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"vscode":{"interpreter":{"hash":"977d1ca4f86cf6796d22eaa6050e2f72f1e03740aa8986f601710bf090b5ff9a"}}},"nbformat":4,"nbformat_minor":0}
