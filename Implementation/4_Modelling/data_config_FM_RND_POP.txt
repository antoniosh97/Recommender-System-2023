asin               6178
reviewerID        14138
overall               5
unixReviewTime     3622
timestamp          3622
year                  1
dtype: int64

####  zero_positions: all data separated by rows  ####
(412392256, 2)

03-Mar-2023  15:52
MODEL: FACTORIZATION MACHINE
epoch 0:
training loss = 1415.6487 | Eval: HR@10 = 0.0021, NDCG@10 = 0.0010 
MODEL: RANDOM
epoch 0:
training loss = 1415.6487 | Eval: HR@10 = 0.0016, NDCG@10 = 0.0007 
MODEL: POPULARITY-BASED
epoch 0:
training loss = 1415.6487 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 1:
training loss = 10.9236 | Eval: HR@10 = 0.0169, NDCG@10 = 0.0119 
MODEL: RANDOM
epoch 1:
training loss = 10.9236 | Eval: HR@10 = 0.0018, NDCG@10 = 0.0009 
MODEL: POPULARITY-BASED
epoch 1:
training loss = 10.9236 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 2:
training loss = 0.5123 | Eval: HR@10 = 0.0255, NDCG@10 = 0.0175 
MODEL: RANDOM
epoch 2:
training loss = 0.5123 | Eval: HR@10 = 0.0014, NDCG@10 = 0.0007 
MODEL: POPULARITY-BASED
epoch 2:
training loss = 0.5123 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 3:
training loss = 0.4961 | Eval: HR@10 = 0.0267, NDCG@10 = 0.0188 
MODEL: RANDOM
epoch 3:
training loss = 0.4961 | Eval: HR@10 = 0.0018, NDCG@10 = 0.0008 
MODEL: POPULARITY-BASED
epoch 3:
training loss = 0.4961 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 4:
training loss = 0.4743 | Eval: HR@10 = 0.0287, NDCG@10 = 0.0194 
MODEL: RANDOM
epoch 4:
training loss = 0.4743 | Eval: HR@10 = 0.0017, NDCG@10 = 0.0008 
MODEL: POPULARITY-BASED
epoch 4:
training loss = 0.4743 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 5:
training loss = 0.4510 | Eval: HR@10 = 0.0277, NDCG@10 = 0.0185 
MODEL: RANDOM
epoch 5:
training loss = 0.4510 | Eval: HR@10 = 0.0014, NDCG@10 = 0.0006 
MODEL: POPULARITY-BASED
epoch 5:
training loss = 0.4510 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 6:
training loss = 0.4313 | Eval: HR@10 = 0.0303, NDCG@10 = 0.0196 
MODEL: RANDOM
epoch 6:
training loss = 0.4313 | Eval: HR@10 = 0.0021, NDCG@10 = 0.0008 
MODEL: POPULARITY-BASED
epoch 6:
training loss = 0.4313 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 7:
training loss = 0.4163 | Eval: HR@10 = 0.0320, NDCG@10 = 0.0203 
MODEL: RANDOM
epoch 7:
training loss = 0.4163 | Eval: HR@10 = 0.0013, NDCG@10 = 0.0005 
MODEL: POPULARITY-BASED
epoch 7:
training loss = 0.4163 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 8:
training loss = 0.4058 | Eval: HR@10 = 0.0335, NDCG@10 = 0.0211 
MODEL: RANDOM
epoch 8:
training loss = 0.4058 | Eval: HR@10 = 0.0021, NDCG@10 = 0.0008 
MODEL: POPULARITY-BASED
epoch 8:
training loss = 0.4058 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 9:
training loss = 0.3977 | Eval: HR@10 = 0.0359, NDCG@10 = 0.0226 
MODEL: RANDOM
epoch 9:
training loss = 0.3977 | Eval: HR@10 = 0.0014, NDCG@10 = 0.0006 
MODEL: POPULARITY-BASED
epoch 9:
training loss = 0.3977 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 10:
training loss = 0.3944 | Eval: HR@10 = 0.0309, NDCG@10 = 0.0206 
MODEL: RANDOM
epoch 10:
training loss = 0.3944 | Eval: HR@10 = 0.0021, NDCG@10 = 0.0009 
MODEL: POPULARITY-BASED
epoch 10:
training loss = 0.3944 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
MODEL: FACTORIZATION MACHINE
epoch 11:
training loss = 0.3908 | Eval: HR@10 = 0.0370, NDCG@10 = 0.0233 
MODEL: RANDOM
epoch 11:
training loss = 0.3908 | Eval: HR@10 = 0.0018, NDCG@10 = 0.0009 
MODEL: POPULARITY-BASED
epoch 11:
training loss = 0.3908 | Eval: HR@10 = 0.0000, NDCG@10 = 0.0000 
_________________________________________________________________
# Training duration: 2833.8205
